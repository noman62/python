{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl5PsRH_bGBz",
        "outputId": "abe11760-f5d3-4364-f97d-3cc949a4da78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras import activations\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from itertools import cycle\n",
        "\n",
        "IMG_SIZE = 299\n",
        "\n",
        "def DataGenerator(train_batch, val_batch, IMG_SIZE):\n",
        "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                 rescale=1.0/255.0,\n",
        "                                 rotation_range=10,\n",
        "                                 horizontal_flip=True,\n",
        "                                 vertical_flip=False)\n",
        "\n",
        "    datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape(1, 1, 3)\n",
        "\n",
        "    train_gen = datagen.flow_from_directory('/content/drive/MyDrive/dihan/archive/train',\n",
        "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                            color_mode='rgb',\n",
        "                                            class_mode='categorical',\n",
        "                                            batch_size=train_batch)\n",
        "\n",
        "    val_gen = datagen.flow_from_directory('/content/drive/MyDrive/dihan/archive/val',\n",
        "                                          target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                          color_mode='rgb',\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size=val_batch)\n",
        "\n",
        "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                 rescale=1.0/255.0)\n",
        "\n",
        "    datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape(1, 1, 3)\n",
        "\n",
        "    test_gen = datagen.flow_from_directory('/content/drive/MyDrive/dihan/archive/test',\n",
        "                                           target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                           color_mode='rgb',\n",
        "                                           batch_size=1,\n",
        "                                           class_mode='categorical',\n",
        "                                           shuffle=False)\n",
        "\n",
        "    return train_gen, val_gen, test_gen\n",
        "\n",
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "class Capsule(Layer):\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3, share_weights=True, activation='squash', **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule, self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule, self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = b + K.batch_dot(hat_inputs, o, [3, 2])\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)\n",
        "\n",
        "input_image = Input(shape=(299, 299, 3))\n",
        "\n",
        "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(299, 299, 3)))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "output = Conv2D(256, kernel_size=(9, 9), strides=(1, 1), activation='relu')(base_model.output)\n",
        "output = Reshape((-1, 256))(output)\n",
        "\n",
        "capsule = Capsule(3, 16, 4, True)(output)\n",
        "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
        "VGGCapsNetmodel = Model(base_model.input, outputs=output)\n",
        "\n",
        "VGGCapsNetmodel.summary()\n",
        "\n",
        "train_batch = 32\n",
        "val_batch = 2\n",
        "train, val, test = DataGenerator(train_batch, val_batch, IMG_SIZE)\n",
        "lr = 1e-4\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"weights.h5\",\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='min')\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min', restore_best_weights=True)\n",
        "\n",
        "callback_list = [checkpoint, early]\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "VGGCapsNetmodel.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=lr, decay=0.001, momentum=0.9), metrics=['accuracy'])\n",
        "\n",
        "hist = VGGCapsNetmodel.fit(train,\n",
        "                           epochs=epochs,\n",
        "                           validation_data=val,\n",
        "                           validation_steps=len(val.classes)//val_batch,\n",
        "                           steps_per_epoch=len(train.classes)//train_batch,\n",
        "                           callbacks=callback_list)\n",
        "\n",
        "pred = VGGCapsNetmodel.predict(test, verbose=1)\n",
        "predicted_classes = np.argmax(np.round(pred), axis=1)\n",
        "\n",
        "# Replace y_test with actual test labels\n",
        "# For demonstration, let's use dummy data for y_test\n",
        "y_test = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])  # Dummy one-hot encoded target labels\n",
        "\n",
        "tar = np.argmax(np.round(y_test), axis=1)\n",
        "\n",
        "print(classification_report(tar, predicted_classes[:len(tar)], target_names=[\"Class 0\", \"Class 1\", \"Class 2\"]))\n",
        "\n",
        "accuracy = hist.history['accuracy']\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'go-', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'ms-', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy curves for VGGCapsNet Model')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'rs-', label='Validation loss')\n",
        "plt.title('Training and validation loss curves for VGGCapsNet Model')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "n_classes = 3\n",
        "lw = 2\n",
        "y_score = pred\n",
        "\n",
        "# Assuming y_test is one-hot encoded\n",
        "target = y_test\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(target[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(target.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"]\n",
        "\n",
        "plt.figure()\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for VGGCapsNet Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "eDkQF8kWreY-",
        "outputId": "9a5d5ce3-58f9-4fc9-e35f-0e5572121601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"capsule_7\" (type Capsule).\n\nin user code:\n\n    File \"<ipython-input-16-06c472c3ccbc>\", line 110, in call  *\n        b = b + K.batch_dot(hat_inputs, o, [3, 2])\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 2584, in batch_dot\n        raise ValueError(\n\n    ValueError: Cannot do batch_dot on inputs with shapes (None, 3, 1, 16) and (None, 3, 3, 16) with axes=[3, 2]. x.shape[3] != y.shape[2] (16 != 3).\n\n\nCall arguments received by layer \"capsule_7\" (type Capsule):\n  • inputs=tf.Tensor(shape=(None, 1, 256), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-06c472c3ccbc>\u001b[0m in \u001b[0;36m<cell line: 127>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mcapsule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mVGGCapsNetmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file_39ibn7r.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file_39ibn7r.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     59\u001b[0m                         \u001b[0;32mnonlocal\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutings\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file_39ibn7r.py\u001b[0m in \u001b[0;36mif_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0;32mnonlocal\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhat_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"capsule_7\" (type Capsule).\n\nin user code:\n\n    File \"<ipython-input-16-06c472c3ccbc>\", line 110, in call  *\n        b = b + K.batch_dot(hat_inputs, o, [3, 2])\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 2584, in batch_dot\n        raise ValueError(\n\n    ValueError: Cannot do batch_dot on inputs with shapes (None, 3, 1, 16) and (None, 3, 3, 16) with axes=[3, 2]. x.shape[3] != y.shape[2] (16 != 3).\n\n\nCall arguments received by layer \"capsule_7\" (type Capsule):\n  • inputs=tf.Tensor(shape=(None, 1, 256), dtype=float32)"
          ]
        }
      ]
    }
  ]
}